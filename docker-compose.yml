version: '3.7'

services:

  ingestion-pipeline:
    image: magiplatform/spark:latest
    container_name: ingestion-pipeline
    entrypoint: tail -f /dev/null
    environment:
      SPARK_MASTER_HOST: spark-master
      SPARK_NUM_EXECUTORS: 2
      SPARK_EXECUTOR_CORES: 2
      SPARK_EXECUTOR_MEMORY: 2g
      SPARK_DRIVER_MEMORY: 2g
      SPARK_DAEMON_MEMORY: 2g
      SPARK_NETWORK_TIMEOUT: 100000
      SPARK_JOB_PARALLELISM: 512
      SPARK_DRIVER_MAX_RESULT_SIZE: 1g
      SPARK_APP_DEBUG: "false"
      ARANGO_HOST: arangodb
    volumes:
      - ./scripts:/opt/app/bin
      - ./target/scala-2.12/ingestion-pipeline-assembly-0.1.0-SNAPSHOT.jar:/opt/spark/jars/app.jar
    depends_on:
      - spark-master
      - kafka
      - zookeeper
    networks:
      - spark

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    restart: always
    networks:
      - spark

  kafka:
    image: wurstmeister/kafka:2.13-2.8.1
    container_name: kafka
    hostname: kafka
    restart: always
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
    networks:
      - spark

  spark-master:
    container_name: spark-master
    hostname: spark-master
    image: magiplatform/spark:latest
    entrypoint: /opt/app/bin/master.sh
    environment:
      SPARK_CORES_MAX: 4
      SPARK_NUM_EXECUTORS: 2
      SPARK_MASTER_HOST: spark-master
      SPARK_DRIVER_MEMORY: 4g
      SPARK_EXECUTOR_CORES: 4
      SPARK_EXECUTOR_MEMORY: 4g
      SPARK_NETWORK_TIMEOUT: 10000
      ARANGO_HOST: arangodb
    ports:
      - "7077:7077"
      - "8080:8080"
      - "6066:6066"
    volumes:
      - ./scripts:/opt/app/scripts
      - ./target/scala-2.12/ingestion-pipeline-assembly-0.1.0-SNAPSHOT.jar:/opt/spark/jars/app.jar
    networks:
      - spark
    depends_on:
      - kafka

  spark-worker-1:
    container_name: spark-worker-1
    hostname: spark-worker-1
    image: magiplatform/spark:latest
    entrypoint: /opt/app/bin/worker.sh
    environment:
      SPARK_CORES_MAX: 4
      SPARK_NUM_EXECUTORS: 2
      SPARK_DRIVER_MEMORY: 2g
      SPARK_EXECUTOR_MEMORY: 2g
      SPARK_NETWORK_TIMEOUT: 10000
    ports:
      - "7078:7078"
      - "8081:8081"
    volumes:
      - ./target/scala-2.12/ingestion-pipeline-assembly-0.1.0-SNAPSHOT.jar:/opt/spark/jars/app.jar
    depends_on:
      - spark-master
    networks:
      - spark

  console:
    image: docker.causeex.com/dart/centos-jdk:jdk8
    container_name: console
    entrypoint: tail -f /dev/null
    volumes:
      - ./docs/pdf:/opt/app/data
    networks:
      - spark

  #  arangodb:
  #    image: docker.causeex.com/dart/dart-arangodb:latest
  #    hostname: arangodb
  #    ports:
  #      - 8529:8529
  #      - 8530:8530
  #    networks:
  #      - spark

  #  minio:
  #    image: quay.io/minio/minio:latest
  #    entrypoint: "minio server start --console-address :9002"
  #    hostname: minio
  #    ports:
  #      - 9002:9002
  #      - 9001:9001
  #      - 9000:9000
  #    networks:
  #      - spark

  #  minio-mc-sidecar:
  #    image: minio/mc:latest
  #    entrypoint: >
  #      /bin/sh -c 'sleep 5; mc alias set dart http://minio:9000 minioadmin minioadmin; mc mb dart/test;'
  #    hostname: minio-mc-sidecar
  #    networks:
  #      - spark

networks:
  spark:
